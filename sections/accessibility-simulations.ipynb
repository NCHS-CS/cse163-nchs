{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessibility Simulations\n",
    "\n",
    "> Inspired by Suh Young Choi.\n",
    "\n",
    "In this section, we will be simulating different types of vision deficiencies: **color blindness** (color vision deficiency) and **blurred vision** (such as near-sightedness or far-sightedness). In the United States, color blindness affects about 1 in 12 men and about 1 in 200 women while blurred vision affects about 1 in 3 people. We can help design more accessible visualizations by simulating different kinds of vision deficiencies using computer vision techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plot = iio.imread(\"plot.png\", mode=\"RGB\")\n",
    "\n",
    "def compare(*images):\n",
    "    \"\"\"Display one or more images side by side.\"\"\"\n",
    "    _, axs = plt.subplots(1, len(images), figsize=(15, 6))\n",
    "    for ax, image in zip(axs, images):\n",
    "        ax.imshow(image, cmap=\"gray\")\n",
    "        ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Monochromatism\n",
    "\n",
    "*Monochromatism* (also called *achromatopsia*) is the rarest form of color vision deficiency, in which an individual has total color blindness. In other words, they see everything in grayscale.\n",
    "\n",
    "Write a function `grayscale` that takes an RGB image and returns a new, single-channel grayscale image with the **weighted average** of the color channels:\n",
    "\n",
    "1. Multiply every value in the **red** channel by 0.3\n",
    "1. Multiply every value in the **green** channel by 0.586\n",
    "1. Multiply every value in the **blue** channel by 0.114\n",
    "1. Add the new red, green, and blue color values for each pixel in the image as a single-channel, grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "    r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    result = ...\n",
    "    return result.clip(0, 255).astype(\"uint8\")\n",
    "\n",
    "\n",
    "compare(plot, grayscale(plot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Protanopia\n",
    "\n",
    "*Protanopia* (pro-tuh-NOPE-ee-uh), also known as red-blindness, is a form of color vision deficiency for red light. A person with protanopia has cones that are less sensitive to red light.\n",
    "\n",
    "Write a function `protanopia` that takes an RGB image and returns a new image with color values weighted according to the formula:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "r_{new} &=& 0.15R + 1.05G - 0.2B \\\\\n",
    "g_{new} &=& 0.11R + 0.79G + 0.1B \\\\\n",
    "b_{new} &=&    0R  -0.05G + 1.05B\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "`np.stack` can be used to recombine separated RGB color channels back into a image with the argument `axis=-1` to \"stack\" the channels along a new, last dimension.\n",
    "\n",
    "```py\n",
    "np.stack([r, g, b], axis=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protanopia(image):\n",
    "    \"\"\"Adjusts the color values of an image to simulate protanopia\"\"\"\n",
    "    r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    return np.stack([\n",
    "        ...,\n",
    "        ...,\n",
    "        ...,\n",
    "    ], axis=-1).clip(0, 255).astype(\"uint8\")\n",
    "\n",
    "\n",
    "compare(plot, protanopia(plot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Deuteranopia\n",
    "\n",
    "Another type of color vision deficiency is called *deuteranopia* (doo-ter-uh-NOPE-ee-uh), or green-blindness. A person with deuteranopia has cones that are less sensitive to green light. Deuteranopia and protanopia are often grouped together under the umbrella term of red-green blindness, since people with either color vision deficiency have difficulty differentiating red and green values. The simulation for deuteranopia will appear very similar to the simulation for protanopia.\n",
    "\n",
    "To simulate deuteranopia, write a function `reweight` that takes an image as well as 3 lists of weights for RGB values and returns a new image with color values reweighted accordingly. The `deuteranopia` function then calls `reweight` with the RGB weights for simulating deuteranopia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(image, r_new, g_new, b_new):\n",
    "    return np.stack([\n",
    "        ...,\n",
    "        ...,\n",
    "        ...,\n",
    "    ], axis=-1).clip(0, 255).astype(\"uint8\")\n",
    "\n",
    "\n",
    "def deuteranopia(image):\n",
    "    return reweight(\n",
    "        image,\n",
    "        [ 0.36, 0.86, -0.22],\n",
    "        [ 0.28, 0.67,  0.05],\n",
    "        [-0.01, 0.04,  0.97],\n",
    "    )\n",
    "\n",
    "\n",
    "compare(plot, deuteranopia(plot))\n",
    "compare(protanopia(plot), deuteranopia(plot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Tritanopia\n",
    "\n",
    "The final type of color vision deficiency we'll simulate is *tritanopia* (try-tuh-NOPE-ee-uh), or blue-blindness. A person with tritanopia has cones that are less sensitive to blue light. The simulation for tritanopia will appear quite different from the simulations for deuteranopia and protanopia.\n",
    "\n",
    "Write a function `tritanopia` that takes an RGB image and returns a new image with color values weighted according to the formula:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "r_{new} &=&  1.26R - 0.08G - 0.18B \\\\\n",
    "g_{new} &=& -0.08R + 0.93G + 0.15B \\\\\n",
    "b_{new} &=&  0R + 0.7G + 0.3B\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Call the `reweight` function in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tritanopia(image):\n",
    "    return ...\n",
    "\n",
    "\n",
    "compare(plot, tritanopia(plot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Blurred Vision\n",
    "\n",
    "In lecture, we learned how to apply convolution to blur a grayscale image. Let's learn how to use convolutions to blur RGB images.\n",
    "\n",
    "Write a function `box_blur` that takes an RGB image and a kernel size and returns the result of applying the specified amount of box blur to the image. The provided convolution code works for grayscale images, but doesn't work for RGB images due to broadcasting errors. Fix the broadcasting error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_blur(image, kernel_size):\n",
    "    # Prepare result shape\n",
    "    image_height, image_width, image_channels = image.shape\n",
    "    result = np.zeros((image_height - kernel_size + 1, image_width - kernel_size + 1, image_channels))\n",
    "    result_height, result_width, result_channels = result.shape\n",
    "\n",
    "    # Setup the box blur kernel as a 2-dimensional square array\n",
    "    kernel = np.array([1 / (kernel_size ** 2)] * (kernel_size ** 2)).reshape((kernel_size, kernel_size))\n",
    "    display(kernel.round(3))\n",
    "\n",
    "    # Apply the kernel via convolution to every subimage\n",
    "    for i in range(result_height):\n",
    "        for j in range(result_width):\n",
    "            subimage = image[i:i + kernel_size, j:j + kernel_size]\n",
    "            result[i, j] = np.sum(subimage * kernel)\n",
    "\n",
    "    return result.clip(0, 255).astype(\"uint8\")\n",
    "\n",
    "\n",
    "compare(plot, box_blur(plot, 9)) # Try changing the kernel size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to simulate blurred vision is **gaussian blur**, which uses a gaussian kernel.\n",
    "\n",
    "First, apply your broadcasting fix by copying your code from the previous `box_blur` function over to the `gaussian_blur` function.\n",
    "\n",
    "Then, write a function `gaussian_kernel` that takes two parameters `n` and `sigma` and returns the `n`-by-`n` gaussian blur kernel, where each element is defined as:\n",
    "\n",
    "$$\n",
    "kernel[i, j] = e^{\\frac{-(i-\\frac{n}{2})^2 + (j-\\frac{n}{2})^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "Call `np.exp(...)` for $e^{(...)}$. When implementing $\\frac{n}{2}$, use floor division by writing `//` instead of `/` to ensure the resulting kernel will be symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(n, sigma):\n",
    "    kernel = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            kernel[i, j] = ...\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "\n",
    "def gaussian_blur(image, kernel_size, smoothing_factor):\n",
    "    # Prepare result shape\n",
    "    image_height, image_width, image_channels = image.shape\n",
    "    result = np.zeros((image_height - kernel_size + 1, image_width - kernel_size + 1, image_channels))\n",
    "    result_height, result_width, result_channels = result.shape\n",
    "\n",
    "    # Setup the box blur kernel as a 2-dimensional square array\n",
    "    kernel = gaussian_kernel(kernel_size, smoothing_factor)\n",
    "    display(kernel.round(3))\n",
    "\n",
    "    # Apply the kernel via convolution to every subimage\n",
    "    for i in range(result_height):\n",
    "        for j in range(result_width):\n",
    "            subimage = image[i:i + kernel_size, j:j + kernel_size]\n",
    "            result[i, j] = np.sum(subimage * kernel)\n",
    "\n",
    "    return result.clip(0, 255).astype(\"uint8\")\n",
    "\n",
    "\n",
    "compare(plot, gaussian_blur(plot, 9, 1)) # Try changing the kernel size and smoothing factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making visualizations accessible to screen readers\n",
    "\n",
    "Beyond simulating color blindness and blurred vision, millions of Americans use screen readers: apps that read the contents of a computer screen aloud (using a generated voice) or Braille. However, visualizations are often inaccessible to screen readers. This is especially the case for visualizations represented as images, but UW researchers have studied how interactive visualizations can be made more accessible as part of the [VoxLens project](https://www.washington.edu/news/2022/06/01/voxlens-adding-one-line-of-code-can-make-some-interactive-visualizations-accessible-to-screen-reader-users/).\n",
    "\n",
    "For visualizations represented as images, adding alternative text (alt text) is one way to help screen readers understand the purpose and information communicated by a visualization. A longer description should typically be made available in the surrounding text as well to give context to the image for all readers. Amy Cesal provides guidance on [Writing Alt Text for Data Visualization](https://nightingaledvs.com/writing-alt-text-for-data-visualization/).\n",
    "\n",
    "In Markdown cells, alt text can be included when embedding an image by writing text within the square brackets:\n",
    "\n",
    "```md\n",
    "![...](plot.png)\n",
    "```\n",
    "\n",
    "Edit the following cell to add a descriptive alt text in the format, \"**Chart type** of **type of data** where **reason for including chart**\" (replacing bolded text appropriately)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plot.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
